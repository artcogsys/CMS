# Cognitive Modeling Suite (CMS)

Framework for neural network modeling and analysis of cognitive processes.
The aim of this framework is to provide a generic approach to training
and testing of neural networks on supervised, unsupervised and reinforcement
learning tasks. It will support life-long learning and the use of multiple
agents at the same time.

For specific resource intensive applications it is adviced to develop
optimized code. Still, snippets from CMS can be of use in that context.


This framework is based on chainer (www.chainer.org).

## Tools

Tools.py contains custom analysis tools that can be applied to neural data
generated by natural and artificial brains. Note that much is provided by
python toolboxes like scikit-learn.

## Agent

This package contains agents that can learn to optimize their parameters. They
are defined by a model and an optimizer. They must implement a *run* function
which implements an update for one minibatch of data. We implement
stateful and stateless agents. They latter uses backpropagation through
time.

#### Supervised

Implements supervised agents

#### Reinforcement

Implements reinforcement learning agents

#### Unsupervised

Implements unsupervised agents (TO DO)

## Brain

This package contains everything necessary to build an agent's brain.

#### Links

Custom links that extend Chainer's capabilities.

#### Models

Models take a predictor (i.e. neural network). They translate the output
of a neural network into usable form. If a model is called then it returns
the loss. The *predict* function allows use of the neural network for making
predictions.

#### Monitor

A monitor is used to monitor the internal states of either a model or a
predictor. It is also used to monitor the past states of an RL agent
to allow RL updating.

#### Networks

Networks are predictors that take input and produce output.

## Examples

Contains examples of how to use CMS

## Sandbox

Work in progress (will be removed in the future)

## World

Contains the machinery to link an agent to a stream of data as implemented by
an iterator. This defines a *world*.

#### Data

Iterators that produce a stream of data. This also takes care of batch
processing. Also contains custom datasets in chainer form that can be
read by data iterators

#### Tasks

Implements various cognitive tasks. Tasks are distinguished from data
in the sense that they produce a data stream as implemented by the
task. Moreover, they can be modulated by agent actions that modify the
state of the task at hand.


## FAQ

How do I test a new network?

* Just write down a model as in networks.py and run it like one of the examples

How do I check particular network states?

* Either examine a stored snapshot or run a snapshot on some test data while monitoring a state. See examples

How do I perform an analysis as the network is learning?

* See test_learning_analysis.py

How do I deal with missing targets?

* Chainer handles missing targets automatically via the value -1. For floats
there is currently no support.

How do I handle trial-based data?

* The SequentialIterator can be used to process a subset of different trials in each epoch.
The reset_state at the onset of each epoch ensures proper resetting. This requires
n_batches to be set to the (fixed) number of time points of which each trial consists.
Also requires that the data is organised as a concatenation of trials.

How do I handle multiple inputs?

* CMS has support for providing a list of datasets as input to a model.

How do I plot intermediate results other than the loss?

* Either define a monitor and set a monitor function (see test_hydranet example)
or do it post hoc on snapshots of the model (see learning analysis example)

## TO DO

* Add example of a task (data will be dependent on network action)
* Add multiple reinforcement learning algorithms
* Add streaming data handling video/audio/linguistic
* Add Universe integration
* Allow networks to run without input and/or output
* Add experiments (fully worked examples
* Add unit testing
* Abstract as much as possible to enable use of other libraries
* Add support for multiple agents in life-long learning setting
* Generate full documentation on the fly using Sphinx/Read the Docs
* Add support for multiple optimizers in Trainer and multiple models in Tester
* Move basic datasets to version testing; keep core codebase as clean
as possible, e.g. by moving part of this code to specific test cases
* Create agents that have train and test modes; but how to best support multiagent.
Agents running on environments
* World should be able to return losses
* Allow input/output/anything visualizer during training; not just loss
  Create generic monitor function; allow multiple monitors that also take
  care of snapshots, loss, throughput; define standard monitors; this
  makes comparison harder; since then each agent gets its own figure window
* Create oscilloscope type monitors
* Reconsider if we want the loss monitoring to implemented by a monitor
* Reconsider if we wish to add multiple monitors to models/predictors
* Think about best integration between CMS and DRM
* Data and task iterators should derive from same type; act option always present
* Generalize monitor such that it takes at most n states (see buffer implementation)
* First implement random RL agent to make it all fit
* Test if we can run multiple RL agents in comparison mode
* Todo: actor-critic model aanvullen; implement run function van actor-critic agent
* Make agent work with multiple batches - batch_size not yet implemented; see Foo
* Implement REINFORCE agent
* RL agent normalize score function by nr of datapoints as return
* Handle initial observations/rewards
* make REINFORCE standalone agent