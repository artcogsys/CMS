# Cognitive Modeling Suite (CMS)

Framework for neural network modeling and analysis of cognitive processes.
The aim of this framework is to provide a generic approach to training
and testing of neural networks on supervised, unsupervised and reinforcement
learning tasks. It will support life-long learning and the use of multiple
agents at the same time.

For specific resource intensive applications it is adviced to develop
optimized code. Still, snippets from CMS can be of use in that context.

## Analysis

Custom analysis tools that can be applied to neural data generated by natural
and artificial brains. Note that much is provided by python toolboxes like
scikit-learn.

### Outline of possible analyses

To do

## Data

Contains datasets and tasks.

## Examples

Examples of how to operate the models.

## Learners

Learning algorithms to train neural networks.
* Algorithms operate on iterators that generate batches based on a dataset or task
* We have Train, Test and Learner objects
* A Train object in combination with an infinite iterator would implement life-long learning

## Models

Different kinds of neural network models.
* A model encapsulates a network (predictor)
* We define custom link functions for e.g. Elman layers
* Monitors can be used to track internal states of models/networks during training and testing

## FAQ

How do I test a new network?

* Just write down a model as in networks.py and run it like one of the examples

How do I check particular network states?

* Either examine a stored snapshot or run a snapshot on some test data while monitoring a state. See examples

How do I perform an analysis as the network is learning?

* See test_learning_analysis.py

How do I deal with missing targets?

* Chainer handles missing targets automatically via the value -1. For floats
there is currently no support.

How do I handle trial-based data?

* The SequentialIterator can be used to process a subset of different trials in each epoch.
The reset_state at the onset of each epoch ensures proper resetting. This requires
n_batches to be set to the (fixed) number of time points of which each trial consists.
Also requires that the data is organised as a concatenation of trials.

How do I handle multiple inputs?

* CMS has support for providing a list of datasets as input to a model.

How do I plot intermediate results other than the loss?

* Either define a monitor and set a monitor function (see test_hydranet example)
or do it post hoc on snapshots of the model (see learning analysis example)

## TO DO

* Add example of a task (data will be dependent on network action)
* Add multiple reinforcement learning algorithms
* Add streaming data handling video/audio/linguistic
* Add Universe integration
* Allow networks to run without input and/or output
* Add experiments (fully worked examples
* Add unit testing
* Abstract as much as possible to enable use of other libraries
* Add support for multiple agents in life-long learning setting
* Generate full documentation on the fly using Sphinx/Read the Docs
* Add support for multiple optimizers in Trainer and multiple models in Tester
* Move basic datasets to version testing; keep core codebase as clean
as possible, e.g. by moving part of this code to specific test cases
* Create agents that have train and test modes; but how to best support multiagent.
Agents running on environments
* World should be able to return losses
* Allow input/output/anything visualizer during training; not just loss
  Create generic monitor function; allow multiple monitors that also take
  care of snapshots, loss, throughput; define standard monitors; this
  makes comparison harder; since then each agent gets its own figure window